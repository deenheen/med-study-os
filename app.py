# app.py
import time
import re
import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
from PIL import Image
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from datetime import datetime

# ==========================================
# 0. Page config
# ==========================================
st.set_page_config(page_title="Med-Study OS", layout="wide", page_icon="ğŸ©º")
st.caption("ğŸ“Œ íë¦„: (1) ì¡±ë³´ DB êµ¬ì¶• â†’ (2,3) ì¡°êµ ì„¤ëª… ë° í¬ì¸íŠ¸ ì¶”ì¶œ â†’ (4) ë‚˜ë§Œì˜ ì •ë¦¬ë…¸íŠ¸ ì™„ì„±")

# ==========================================
# 1. Session state
# ==========================================
if "db" not in st.session_state:
    st.session_state.db = []

if "api_key" not in st.session_state:
    st.session_state.api_key = None

if "api_key_ok" not in st.session_state:
    st.session_state.api_key_ok = False

if "text_models" not in st.session_state:
    st.session_state.text_models = []

if "best_text_model" not in st.session_state:
    st.session_state.best_text_model = None

if "lecture_doc" not in st.session_state:
    st.session_state.lecture_doc = None

if "lecture_filename" not in st.session_state:
    st.session_state.lecture_filename = None

if "current_page" not in st.session_state:
    st.session_state.current_page = 0

# caches for Tab 2
if "last_page_sig" not in st.session_state:
    st.session_state.last_page_sig = None

if "last_ai_sig" not in st.session_state:
    st.session_state.last_ai_sig = None

if "last_ai_text" not in st.session_state:
    st.session_state.last_ai_text = ""

if "last_related" not in st.session_state:
    st.session_state.last_related = []

# caches for Tab 3
if "last_transcript_result" not in st.session_state:
    st.session_state.last_transcript_result = ""

# Storage for Summary Notes (Tab 4)
if "my_notes" not in st.session_state:
    # item: {"id": str, "source": str, "content": str, "timestamp": str}
    st.session_state.my_notes = []

# ==========================================
# 2. Settings
# ==========================================
JOKBO_THRESHOLD = 0.72  # ì¶”ì²œ 0.70~0.75

def has_jokbo_evidence(related: list[dict]) -> bool:
    return bool(related) and related[0]["score"] >= JOKBO_THRESHOLD

# ==========================================
# 3. Utils
# ==========================================
def ensure_configured():
    if st.session_state.get("api_key"):
        genai.configure(api_key=st.session_state["api_key"])

def extract_text_from_pdf(uploaded_file):
    data = uploaded_file.getvalue()
    doc = fitz.open(stream=data, filetype="pdf")
    pages = []
    for i, page in enumerate(doc):
        text = page.get_text() or ""
        if text.strip():
            pages.append({"page": i + 1, "text": text, "source": uploaded_file.name})
    return pages

def get_embedding(text: str):
    text = (text or "").strip()
    if not text:
        return []
    text = text[:12000]
    ensure_configured()
    try:
        return genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document",
        )["embedding"]
    except Exception:
        try:
            return genai.embed_content(
                model="models/embedding-001",
                content=text,
                task_type="retrieval_document",
            )["embedding"]
        except Exception:
            return []

def filter_db_by_subject(subject: str, db: list[dict]):
    if not db:
        return []
    subject = (subject or "").strip()
    if subject in ["ì „ì²´", "ALL", ""]:
        return db
    return [x for x in db if x.get("subject") == subject]

def find_relevant_jokbo(query_text: str, db: list[dict], top_k: int = 5):
    if not db:
        return []
    query_emb = get_embedding(query_text)
    if not query_emb:
        return []
    valid_items = [item for item in db if item.get("embedding")]
    if not valid_items:
        return []
    db_embs = [item["embedding"] for item in valid_items]
    sims = cosine_similarity([query_emb], db_embs)[0]
    top_idxs = np.argsort(sims)[::-1][:top_k]
    return [{"score": float(sims[i]), "content": valid_items[i]} for i in top_idxs]

def add_to_notes(source_type: str, content: str):
    """ë…¸íŠ¸ ì €ì¥ í•¨ìˆ˜"""
    new_note = {
        "id": str(time.time()),
        "source": source_type,
        "content": content,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M")
    }
    st.session_state.my_notes.append(new_note)
    st.toast("âœ… ì •ë¦¬ë…¸íŠ¸ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!", icon="ğŸ“")

# ==========================================
# 4. AI (ì¡°êµ ì„¤ëª…)
# ==========================================
@st.cache_data(show_spinner=False)
def list_text_models(api_key: str):
    genai.configure(api_key=api_key)
    models = genai.list_models()
    out = []
    for m in models:
        methods = getattr(m, "supported_generation_methods", []) or []
        if "generateContent" in methods:
            out.append(m.name)
    return out

def pick_best_text_model(model_names: list[str]):
    if not model_names:
        return None
    flash = [m for m in model_names if "flash" in m.lower()]
    return flash[0] if flash else model_names[0]

def generate_with_fallback(prompt: str, model_names: list[str]):
    ensure_configured()
    last_err = None
    for name in model_names:
        if not name:
            continue
        try:
            model = genai.GenerativeModel(name)
            res = model.generate_content(prompt)
            text = getattr(res, "text", None)
            if text:
                return text, name
            return str(res), name
        except Exception as e:
            last_err = e
    raise last_err

def build_ta_prompt(lecture_text: str, related: list[dict], subject: str):
    ctx_lines = []
    for r in related[:3]:
        c = r["content"]
        src = c.get("source", "")
        pg = c.get("page", "?")
        txt = (c.get("text") or "")[:450]
        ctx_lines.append(f'- [{src} p{pg} | sim={r["score"]:.3f}] {txt}')
    jokbo_ctx = "\n".join(ctx_lines)

    return f"""
ë„ˆëŠ” ì˜ëŒ€ ì¡°êµë‹¤. í•™ìƒì´ ê°•ì˜ë¥¼ ë“£ëŠ” ì¤‘ì´ë©°, ì§€ê¸ˆ í…ìŠ¤íŠ¸ê°€ ì¡±ë³´ì—ì„œ ì–´ë–¤ ì‹ìœ¼ë¡œ ì¶œì œë˜ì—ˆëŠ”ì§€ ì„¤ëª…í•´ë¼.
ê³¼ëª©: {subject}

ê·œì¹™:
- [ê´€ë ¨ ì¡±ë³´ ë°œì·Œ]ì— ê·¼ê±°í•´ì„œë§Œ ë§í•´ë¼.
- ê°•ì˜ í…ìŠ¤íŠ¸ë¥¼ ê¸¸ê²Œ ë‹¤ì‹œ ë§í•˜ì§€ ë§ê³ , "ì¡±ë³´ ì¶œì œ í¬ì¸íŠ¸" ìœ„ì£¼ë¡œ ìš”ì•½í•´ë¼.

ì¶œë ¥ í˜•ì‹:
**[ì¡°êµ ì½”ë©˜íŠ¸]**
(í•µì‹¬ ìš”ì•½ 1ë¬¸ì¥)

**[ì¡±ë³´ ê¸°ì¶œ í¬ì¸íŠ¸]**
- (í¬ì¸íŠ¸ 1)
- (í¬ì¸íŠ¸ 2)

**[ë¬¸ì œ ìœ í˜•]** (ê°ê´€ì‹/ì„œìˆ í˜•/ë¹ˆì¹¸ ë“±)

**[ì•”ê¸° í‚¤ì›Œë“œ]**
í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2...

[ì…ë ¥ í…ìŠ¤íŠ¸]
{lecture_text}

[ê´€ë ¨ ì¡±ë³´ ë°œì·Œ]
{jokbo_ctx}
""".strip()

def build_transcript_prompt(chunks: list[str], related_packs: list[list[dict]], subject: str):
    lines = []
    for idx, (chunk, rel) in enumerate(zip(chunks, related_packs), start=1):
        if not has_jokbo_evidence(rel):
            continue
        ctx = []
        for r in rel[:2]:
            c = r["content"]
            ctx.append(f'- [{c.get("source","")} p{c.get("page","?")} sim={r["score"]:.3f}] {(c.get("text","")[:250])}')
        lines.append(f"""
(êµ¬ê°„ {idx})
[ê°•ì˜ ì „ì‚¬ ì¼ë¶€]
{chunk}

[ê´€ë ¨ ì¡±ë³´ ë°œì·Œ]
{chr(10).join(ctx)}
""".strip())

    packed = "\n\n".join(lines)
    if not packed.strip():
        packed = "(ì¡±ë³´ ê·¼ê±°ê°€ ìˆëŠ” êµ¬ê°„ì´ ì—†ìŠµë‹ˆë‹¤.)"

    return f"""
ë„ˆëŠ” ì˜ëŒ€ ì¡°êµë‹¤. ì•„ë˜ëŠ” ê°•ì˜ ì „ì‚¬ í…ìŠ¤íŠ¸ë‹¤.
'ì¡±ë³´ì— ì‹¤ì œë¡œ ë‚˜ì™”ë˜ ë‚´ìš©'ë§Œ ê³¨ë¼ ì •ë¦¬í•´ë¼.
ê³¼ëª©: {subject}

ê·œì¹™:
- ë°˜ë“œì‹œ [ê´€ë ¨ ì¡±ë³´ ë°œì·Œ] ê·¼ê±°ê°€ ìˆëŠ” êµ¬ê°„ë§Œ í¬í•¨í•´ë¼.
- ì¶œë ¥ì€ "ì¡±ë³´ í¬ì¸íŠ¸ ë…¸íŠ¸" í˜•íƒœë¡œ ê°„ê²°í•˜ê²Œ.

ì¶œë ¥ í˜•ì‹:
## ì¡±ë³´ í¬ì¸íŠ¸ ì •ë¦¬
1. **(ì£¼ì œ)**
   - ë‚´ìš©: ...
   - ê·¼ê±°: (íŒŒì¼ëª…/í˜ì´ì§€)
   - ì•”ê¸°: ...

2. **(ì£¼ì œ)**
   ...

ì…ë ¥ ë°ì´í„°:
{packed}
""".strip()

# ==========================================
# 5. Transcript chunking
# ==========================================
def chunk_transcript(text: str, max_chars: int = 900):
    text = (text or "").strip()
    if not text:
        return []
    parts = [p.strip() for p in re.split(r"\n\s*\n", text) if p.strip()]
    chunks = []
    for p in parts:
        if len(p) <= max_chars:
            chunks.append(p)
        else:
            start = 0
            while start < len(p):
                chunks.append(p[start:start + max_chars])
                start += max_chars
    return chunks

# ==========================================
# 6. Sidebar
# ==========================================
with st.sidebar:
    st.title("ğŸ©º Med-Study")

    api_key = st.text_input("Gemini API Key", type="password", key="api_key_input")
    if api_key:
        try:
            st.session_state.api_key = api_key
            genai.configure(api_key=api_key)
            available_models = list_text_models(api_key)
            if not available_models:
                st.session_state.api_key_ok = False
                st.error("generateContent ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.session_state.api_key_ok = True
                st.session_state.text_models = available_models
                st.session_state.best_text_model = pick_best_text_model(available_models)
                st.success("AI ì—°ê²° ì™„ë£Œ")
                st.caption(f"í…ìŠ¤íŠ¸ ëª¨ë¸(ìë™): {st.session_state.best_text_model}")
        except Exception as e:
            st.session_state.api_key_ok = False
            st.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    st.divider()

    subjects_in_db = sorted({x.get("subject", "") for x in st.session_state.db if x.get("subject")})
    st.caption(f"ğŸ“š í•™ìŠµëœ ì¡±ë³´ í˜ì´ì§€: **{len(st.session_state.db)}**")
    st.caption(f"ğŸ“š ê³¼ëª©: **{', '.join(subjects_in_db) if subjects_in_db else '(ì—†ìŒ)'}**")

    if st.button("ì¡±ë³´ DB ì´ˆê¸°í™”", key="reset_db_btn"):
        st.session_state.db = []
        st.session_state.last_page_sig = None
        st.session_state.last_ai_sig = None
        st.session_state.last_ai_text = ""
        st.session_state.last_related = []
        st.session_state.last_transcript_result = ""
        st.session_state.my_notes = []
        st.rerun()

# ==========================================
# 7. Tabs
# ==========================================
tab1, tab2, tab3, tab4 = st.tabs(
    ["ğŸ“‚ 1) ì¡±ë³´ DB êµ¬ì¶•", "ğŸ“– 2) ê°•ì˜ë³¸ + ì¡°êµ", "ğŸ™ï¸ 3) ì „ì‚¬ í…ìŠ¤íŠ¸ + ì¡°êµ", "ğŸ“ 4) ë‚˜ë§Œì˜ ì •ë¦¬ë…¸íŠ¸"]
)

# ==================================================
# TAB 1 â€” Upload
# ==================================================
with tab1:
    st.header("ğŸ“‚ 1) ê³¼ëª©ë³„ ì¡±ë³´ ì—…ë¡œë“œ/í•™ìŠµ")
    
    c1, c2 = st.columns([1, 2])
    with c1:
        subject_for_upload = st.selectbox("ê³¼ëª©", ["í•´ë¶€í•™", "ìƒë¦¬í•™", "ì•½ë¦¬í•™", "ê¸°íƒ€(ì§ì ‘ì…ë ¥)"], index=1)
    with c2:
        subject_custom = st.text_input("ê¸°íƒ€ ê³¼ëª©ëª…", disabled=(subject_for_upload != "ê¸°íƒ€(ì§ì ‘ì…ë ¥)"))

    subject_final = subject_custom.strip() if subject_for_upload == "ê¸°íƒ€(ì§ì ‘ì…ë ¥)" else subject_for_upload
    subject_final = subject_final if subject_final else "ê¸°íƒ€(ë¯¸ì…ë ¥)"

    files = st.file_uploader("ì¡±ë³´ PDF ì—…ë¡œë“œ", type="pdf", accept_multiple_files=True)
    max_pages = st.number_input("íŒŒì¼ë‹¹ ìµœëŒ€ í•™ìŠµ í˜ì´ì§€", 1, 500, 60)

    if st.button("ğŸ“š ì¡±ë³´ DB êµ¬ì¶• ì‹œì‘", key="build_db_btn"):
        if not st.session_state.api_key_ok:
            st.error("API Key í•„ìš”")
            st.stop()
        if not files:
            st.warning("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            st.stop()

        bar = st.progress(0)
        status = st.empty()
        new_db = []
        total_files = len(files)

        for i, f in enumerate(files):
            status.text(f"ğŸ“– ì²˜ë¦¬ ì¤‘: {f.name}")
            pages = extract_text_from_pdf(f)[: int(max_pages)]
            if not pages:
                continue
            for j, p in enumerate(pages):
                emb = get_embedding(p["text"])
                if emb:
                    p["embedding"] = emb
                    p["subject"] = subject_final
                    new_db.append(p)
                time.sleep(0.7)
            bar.progress((i + 1) / total_files)

        st.session_state.db.extend(new_db)
        status.text("âœ… ì™„ë£Œ")
        st.success(f"[{subject_final}] {len(new_db)} í˜ì´ì§€ í•™ìŠµ ì™„ë£Œ")

# ==================================================
# TAB 2 â€” PDF Viewer + TA
# ==================================================
with tab2:
    st.header("ğŸ“– 2) ê°•ì˜ë³¸(PDF) â†’ ì¡°êµ ì„¤ëª…")
    
    if not st.session_state.db:
        st.warning("ë¨¼ì € 1ë²ˆ íƒ­ì—ì„œ ì¡±ë³´ DBë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.")

    subjects_in_db = sorted({x.get("subject", "") for x in st.session_state.db if x.get("subject")})
    subject_options = ["ì „ì²´"] + (subjects_in_db if subjects_in_db else ["(DB ì—†ìŒ)"])
    subject_pick = st.selectbox("ë¶„ì„ ê³¼ëª©", subject_options, key="tab2_sub")
    
    lec_file = st.file_uploader("ê°•ì˜ë³¸ PDF ì—…ë¡œë“œ", type="pdf", key="lec_pdf")

    if lec_file:
        if st.session_state.lecture_doc is None or st.session_state.lecture_filename != lec_file.name:
            data = lec_file.getvalue()
            st.session_state.lecture_doc = fitz.open(stream=data, filetype="pdf")
            st.session_state.lecture_filename = lec_file.name
            st.session_state.current_page = 0
            st.session_state.last_ai_text = ""

        doc = st.session_state.lecture_doc
        col_view, col_right = st.columns([6, 4])

        with col_view:
            nav1, nav2, nav3 = st.columns([1, 2, 1])
            if nav1.button("â—€", key="prev"):
                if st.session_state.current_page > 0: st.session_state.current_page -= 1
            nav2.markdown(f"<center><b>{st.session_state.current_page+1} / {len(doc)}</b></center>", unsafe_allow_html=True)
            if nav3.button("â–¶", key="next"):
                if st.session_state.current_page < len(doc) - 1: st.session_state.current_page += 1

            page = doc.load_page(st.session_state.current_page)
            pix = page.get_pixmap(dpi=150)
            st.image(Image.frombytes("RGB", [pix.width, pix.height], pix.samples), use_container_width=True)
            page_text = (page.get_text() or "").strip()

        with col_right:
            st.markdown("### ğŸ§‘â€ğŸ« ì¡°êµ ì„¤ëª…")
            
            db_sub = filter_db_by_subject(subject_pick, st.session_state.db)
            page_sig = hash(page_text)
            
            # í˜ì´ì§€ ë³€ê²½ ê°ì§€ ì‹œ DB ê²€ìƒ‰
            if page_sig != st.session_state.last_page_sig:
                st.session_state.last_page_sig = page_sig
                st.session_state.last_related = find_relevant_jokbo(page_text, db_sub) if page_text else []
                st.session_state.last_ai_sig = None 

            related = st.session_state.last_related
            
            if not page_text:
                st.info("í…ìŠ¤íŠ¸ ì—†ìŒ")
            elif not has_jokbo_evidence(related):
                st.info("ğŸ’¡ ì´ í˜ì´ì§€ëŠ” ì¡±ë³´ì™€ ì§ì ‘ì  ì—°ê´€ì´ ì ìŠµë‹ˆë‹¤.")
            else:
                # AI ìƒì„±
                ai_sig = (page_sig, subject_pick)
                if ai_sig != st.session_state.last_ai_sig:
                    if st.session_state.api_key_ok:
                        prompt = build_ta_prompt(page_text, related, subject_pick)
                        with st.spinner("ë¶„ì„ ì¤‘..."):
                            res, _ = generate_with_fallback(prompt, st.session_state.text_models)
                        st.session_state.last_ai_text = res
                        st.session_state.last_ai_sig = ai_sig

                st.write(st.session_state.last_ai_text)
                
                # --- [ê¸°ëŠ¥ ì¶”ê°€] ë…¸íŠ¸ ì €ì¥ ë²„íŠ¼ ---
                if st.session_state.last_ai_text:
                    st.divider()
                    col_save, _ = st.columns([1, 2])
                    if col_save.button("ğŸ“Œ ì´ ë‚´ìš© ë…¸íŠ¸ì— ì €ì¥", key="save_tab2"):
                        note_content = f"[ê°•ì˜ë³¸ p{st.session_state.current_page+1}]\n{st.session_state.last_ai_text}"
                        add_to_notes("ê°•ì˜ë³¸(PDF)", note_content)

# ==================================================
# TAB 3 â€” Transcript
# ==================================================
with tab3:
    st.header("ğŸ™ï¸ 3) ê°•ì˜ ì „ì‚¬ í…ìŠ¤íŠ¸ â†’ ì¡±ë³´ í¬ì¸íŠ¸")
    
    subjects_in_db = sorted({x.get("subject", "") for x in st.session_state.db if x.get("subject")})
    subject_options = ["ì „ì²´"] + (subjects_in_db if subjects_in_db else ["(DB ì—†ìŒ)"])
    subject_pick = st.selectbox("ë¶„ì„ ê³¼ëª©", subject_options, key="tab3_sub")

    transcript_text = st.text_area("ì „ì‚¬ í…ìŠ¤íŠ¸ ì…ë ¥", height=200)
    max_chunks = st.number_input("ìµœëŒ€ ë¶„ì„ êµ¬ê°„ ìˆ˜", 1, 40, 10)

    if st.button("ğŸ§  ì¡±ë³´ í¬ì¸íŠ¸ ë½‘ê¸°", key="run_transcript"):
        if not transcript_text.strip():
            st.error("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            st.stop()
        
        db_sub = filter_db_by_subject(subject_pick, st.session_state.db)
        chunks = chunk_transcript(transcript_text, 900)[:int(max_chunks)]
        
        related_packs = []
        prog = st.progress(0)
        for i, ch in enumerate(chunks, 1):
            rel = find_relevant_jokbo(ch, db_sub, top_k=3)
            related_packs.append(rel)
            prog.progress(i / len(chunks))
        
        prompt = build_transcript_prompt(chunks, related_packs, subject_pick)
        with st.spinner("ì¡±ë³´ ë§¤ì¹­ ì¤‘..."):
            result, _ = generate_with_fallback(prompt, st.session_state.text_models)
        
        st.session_state.last_transcript_result = result
        st.success("ë¶„ì„ ì™„ë£Œ!")

    # ê²°ê³¼ í‘œì‹œ ë° ì €ì¥
    if st.session_state.last_transcript_result:
        st.markdown("### ğŸ§‘â€ğŸ« ì¡±ë³´ í¬ì¸íŠ¸ ë…¸íŠ¸")
        st.write(st.session_state.last_transcript_result)
        
        st.divider()
        if st.button("ğŸ“Œ ì´ í¬ì¸íŠ¸ ë…¸íŠ¸ì— ì €ì¥", key="save_tab3"):
            add_to_notes("ì „ì‚¬í…ìŠ¤íŠ¸", st.session_state.last_transcript_result)

# ==================================================
# TAB 4 â€” Summary Notes (NEW)
# ==================================================
with tab4:
    st.header("ğŸ“ ë‚˜ë§Œì˜ ì •ë¦¬ë…¸íŠ¸")
    st.caption("ê°•ì˜ë³¸ê³¼ ì „ì‚¬ í…ìŠ¤íŠ¸ì—ì„œ ì €ì¥í•œ í•µì‹¬ ë‚´ìš©ë“¤ì„ ëª¨ì•„ë´…ë‹ˆë‹¤.")

    if not st.session_state.my_notes:
        st.info("ì•„ì§ ì €ì¥ëœ ë…¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. Tab 2, 3ì—ì„œ 'ğŸ“Œ ì €ì¥' ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”.")
    else:
        # ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
        full_text = ""
        for note in st.session_state.my_notes:
            full_text += f"[{note['timestamp']} | {note['source']}]\n{note['content']}\n\n{'='*30}\n\n"
        
        st.download_button(
            label="ğŸ“¥ ì „ì²´ ë…¸íŠ¸ ë‹¤ìš´ë¡œë“œ (TXT)",
            data=full_text,
            file_name=f"My_Med_Note_{datetime.now().strftime('%m%d')}.txt",
            mime="text/plain"
        )
        
        st.divider()

        # ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ (ì—­ìˆœ: ìµœì‹ ìˆœ)
        for i, note in enumerate(reversed(st.session_state.my_notes)):
            # Index handling for deletion logic is tricky with reversed, so use original index/ID
            real_index = len(st.session_state.my_notes) - 1 - i
            
            with st.expander(f"ğŸ“ ë…¸íŠ¸ #{i+1} ({note['source']} - {note['timestamp']})", expanded=True):
                col_content, col_del = st.columns([9, 1])
                
                with col_content:
                    st.markdown(note['content'])
                
                with col_del:
                    if st.button("ğŸ—‘ï¸", key=f"del_{note['id']}"):
                        st.session_state.my_notes.pop(real_index)
                        st.rerun()
        try:
            valid_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            if valid_models:
                st.success(f"âœ… ì—°ê²° ì„±ê³µ! ({len(valid_models)}ê°œ ëª¨ë¸ ê°ì§€)")
                with st.expander("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡"):
                    st.write(valid_models)
            else:
                st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"âš ï¸ API ì—°ê²° ì‹¤íŒ¨: {e}")

    st.divider()
    st.markdown("### ìƒíƒœ ëª¨ë‹ˆí„°")
    if st.session_state.jokbo_done:
        st.info("ğŸ“š ì¡±ë³´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

# =========================
# 2. í•µì‹¬ í•¨ìˆ˜ (ì„ë² ë”© ë° ë¶„ì„)
# =========================

def get_embedding(text):
    try:
        # ëª¨ë¸ëª…ì€ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ì„ë² ë”© ëª¨ë¸ë¡œ í™•ì¸ í•„ìš”
        result = genai.embed_content(
            model="models/embedding-001",
            content=text,
            task_type="retrieval_document"
        )
        return result['embedding']
    except Exception as e:
        print(f"ì„ë² ë”© ì—ëŸ¬: {e}")
        return None

def display_pdf_as_image(file_bytes, page_num):
    try:
        doc = fitz.open(stream=file_bytes, filetype="pdf")
        page_idx = page_num - 1
        if 0 <= page_idx < len(doc):
            page = doc.load_page(page_idx)
            mat = fitz.Matrix(2, 2)  # í•´ìƒë„ 2ë°°
            pix = page.get_pixmap(matrix=mat)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            st.image(img, use_container_width=True)
        doc.close()
    except Exception as e:
        st.error(f"PDF ë Œë”ë§ ì˜¤ë¥˜: {e}")

def analyze_connection(lecture_text, jokbo_text):
    if not api_key: return "AI ì—°ê²° í•„ìš”"

    prompt = f"""
    ë‹¹ì‹ ì€ ì˜í•™ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ë‹¤ìŒ 'ê°•ì˜ë¡ ë‚´ìš©'ê³¼ 'ê³¼ê±° ì¡±ë³´(ê¸°ì¶œ)' ì‚¬ì´ì˜ ì—°ê´€ì„±ì„ ë¶„ì„í•˜ì„¸ìš”.
    
    [ê°•ì˜ë¡]: {lecture_text}
    [ì¡±ë³´]: {jokbo_text}
    
    **ë¶„ì„:** (í•œ ì¤„ ìš”ì•½)
    """

    try:
        # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        valid_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        if not valid_models:
            return "ë¶„ì„ ì‹¤íŒ¨: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤."

        # 2. ìµœì ì˜ ëª¨ë¸ ì„ íƒ (Flash > Pro > ìˆœì„œ)
        best_model = valid_models[0]
        for m in valid_models:
            if 'flash' in m.lower():
                best_model = m
                break
            elif 'pro' in m.lower():
                best_model = m
        
        # 3. ëª¨ë¸ ì‹¤í–‰
        model = genai.GenerativeModel(best_model)
        response = model.generate_content(prompt)
        return response.text 
    except Exception as e:
        return f"ë¶„ì„ ì—ëŸ¬: {e}"

# =========================
# 3. ë©”ì¸ UI ë° ë¡œì§
# =========================
st.title("ğŸ©º Med-Study OS: Final Ver.")

tab1, tab2 = st.tabs(["ğŸ“‚ ë°ì´í„° í•™ìŠµ (ì¤€ë¹„)", "ğŸ“– ê°•ì˜ ë·°ì–´ (ê³µë¶€)"])

with tab1:
    st.subheader("1. ì¡±ë³´(ê¸°ì¶œ) PDF ì—…ë¡œë“œ")
    jokbo_files = st.file_uploader("ì—¬ëŸ¬ ê°œì˜ ì¡±ë³´ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.", accept_multiple_files=True, type="pdf")
    
    if jokbo_files and not st.session_state.jokbo_done:
        if st.button("ì¡±ë³´ í•™ìŠµ ì‹œì‘ âš¡"):
            all_exams = []
            embeddings = []
            bar = st.progress(0)
            
            for idx, f in enumerate(jokbo_files):
                # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì„ë² ë”© ë¡œì§ (ê°„ëµí™”)
                # ... (ì‹¤ì œ êµ¬í˜„ ì‹œ ì—¬ê¸°ì— PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§ ì¶”ê°€)
                time.sleep(0.3) # âš¡ ì†ë„ ê°œì„ ì„ ìœ„í•œ ëŒ€ê¸° ì‹œê°„ ì¡°ì •
                bar.progress((idx + 1) / len(jokbo_files))
            
            st.session_state.jokbo_done = True
            st.success("í•™ìŠµ ì™„ë£Œ!")

with tab2:
    st.subheader("2. ê°•ì˜ë¡ ë¶„ì„ ë° ë·°ì–´")
    lecture_file = st.file_uploader("ì˜¤ëŠ˜ ê³µë¶€í•  ê°•ì˜ë¡ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="pdf")
    
    if lecture_file:
        # ê°•ì˜ë¡ ì²˜ë¦¬ ë¡œì§
        if st.button("ê°•ì˜ë¡ ë¶„ì„ ì‹œì‘ ğŸ”"):
            if not st.session_state.jokbo_done:
                st.error("ì¡±ë³´ í•™ìŠµì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”!")
            else:
                with st.spinner("AIê°€ ê°•ì˜ë¡ê³¼ ì¡±ë³´ë¥¼ ëŒ€ì¡° ì¤‘..."):
                    # ë¶„ì„ ë£¨í”„
                    # response = analyze_connection(text, context)
                    # time.sleep(0.3) # Flash ëª¨ë¸ ìµœì í™” ëŒ€ê¸° ì‹œê°„
                    st.session_state.lecture_done = True
                    st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

